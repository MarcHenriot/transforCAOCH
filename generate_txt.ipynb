{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tjRdl4TboWe",
        "outputId": "ec10be9f-3653-4954-9fa5-463c16780ee1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 29.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SzeBSA_UlsSd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gdown\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/drive/folders/1GdEtbxBPpsilJb21ZY6aP2oM1lkARgzu?usp=sharing\"\n",
        "gdown.download_folder(url, quiet=True, use_cookies=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLtYZ8nW6l0a",
        "outputId": "79d87229-9941-4c19-9315-cbb54175492b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/model_save/added_tokens.json',\n",
              " '/content/model_save/config.json',\n",
              " '/content/model_save/merges.txt',\n",
              " '/content/model_save/pytorch_model.bin',\n",
              " '/content/model_save/special_tokens_map.json',\n",
              " '/content/model_save/tokenizer_config.json',\n",
              " '/content/model_save/vocab.json']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"model_save\"\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "c-d9NhNLmSZn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(path, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>', local_files_only=True)\n",
        "configuration = GPT2Config.from_pretrained(path, output_hidden_states=False, local_files_only=True)\n",
        "model = GPT2LMHeadModel.from_pretrained(path, config=configuration, local_files_only=True)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncf84H2Kl9Z4",
        "outputId": "0c267381-60e2-4eae-b238-94b84c18016c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50259, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.eval()\n",
        "prompt = \"<|startoftext|>\"\n",
        "film_title = \"Transformers 2\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt + film_title)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    generated, \n",
        "    do_sample=True,   \n",
        "    top_k=50, \n",
        "    max_length=400,\n",
        "    top_p=0.95, \n",
        "    num_return_sequences=3\n",
        ")\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(f\"{i}: {tokenizer.decode(sample_output, skip_special_tokens=True)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtuOJFOCl3wf",
        "outputId": "7e8bcc6b-7d89-457a-b1ff-d104f4f629b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50257, 41762,   364,   362]], device='cuda:0')\n",
            "0: Transformers 2 : A mon premier visionnage sur l’âme. Vraiment, je suis vraiment très client de ce genre de visionnage de nos jours. Vraiment, on a le droit à un univers assez noir et créatif que le premier visionnage. De plus, il y a une vrai ordure de romanesque. Mais c’est surtout la trame qui est juste mythique et très génial. La réalisation est comme d’habitude (dans les années 80) : vraiment très efficace et très inspiré, la mise en scène est excellente, les effets spéciaux de fée si sont très réussit et des ralentis assez impressionnant. Les décors, costume sont juste excellente et les décors et effets spéciaux sont juste magistrale : moi je dis : bravo. Et les acteurs sont tous très convaincant et joue très bien leur rôle. Voila, une suite efficace et maitrisé, très divertissent et prenant comme il le faut. Vraiment, on se prend avec plaisir et on retrouve aussi nos jours dans tous ces studios. A voir, une grand réussit.\n",
            "\n",
            "\n",
            "1: Transformers 2 : Après un premier épisode de la série des méchants les plus cultes du cinéma : action, humour et clin œil aux cartoons. Cette suite est tout aussi excellent et remplit d’humour avec un scénario plus qu’un peu crédible : méchant avec les enfants… Cette nouvelle aventure est rythmée aussi dynamique et captivante du début jusqu'à la fin : on nous présente dans tous les sens et nous met KO au premier opus et nous laisse suffisamment pour une autre suite et cela pourrait gêner un peu le moins. Après un premier épisode qui est divertissant et bien mené. Car, cet épisode est remplit de clin œil au premier film. On reconnait qu’un puissant et génial de voir Jason Statham a le droit a une véritable rôle : toujours aussi imposant, toujours aussi intelligent et toujours aussi réussit car il est parfait dans ce film. Et les autres personnages sont très sympa et joue à la perfection. Voila, un deuxième de la série mais un deuxième des plus cultes. Tout simplement : c’est un classique devenu culte. Remplit d’action, de clin œil aux cartoons avec un super série qui est juste énorme. De plus, le scénario est bien rythmé, l’\n",
            "\n",
            "\n",
            "2: Transformers 2 : Ah ouais!!! De l’action spectaculaire et spectaculaire, le début d’une redoutable efficacité redoutable, un peu n’égalera jamais : on a le droit au niveau de la réalisation et la mise en scène, vraiment la réalisation est génial, c’est superbe et la mise en scène sublime. A ouais j’ai nommé : Brad Bird qui joue Arnold Schwarzenegger toujours aussi bien et il joue le rôle du héros et ça c’est super comme d’habitude : mémorable et très impressionnants. Après un scénario bien ficelé et captivant avec une pointe d’humour qui fait plaisir, même l’histoire est remplit de scène vraiment pas mal, j’ai adoré la scène de combat et des combats vraiment magnifiquement bien chorégraphié ( spoiler: vraiment l’héros très réussit ). Enfin voila, ce qui a de bien dans ce film, c’est que c’est le méchant qui est parfaite de l’action, j’ai était prit du début jusqu'à la fin et ça j’ai adoré, c’est un combat explosif d’une redoutable efficacité redoutable et ça c’est bien. Ensuite, les musiques collent parfaitement à\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8OS5i56y6723"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "generate_txt.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}