{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "title = \"Transformers 2\"\n",
        "meta = \"Action, Aventure, Science fiction, Thriller\"\n",
        "director = \"Michael Bay\"\n",
        "cast = \"Shia LaBeouf, Megan Fox, Josh Duhamel\""
      ],
      "metadata": {
        "id": "LKgDnYY8c2sG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tjRdl4TboWe",
        "outputId": "684d5a15-1448-4aaa-a3bd-35498bad7bb5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 41.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SzeBSA_UlsSd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gdown\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/drive/folders/1rlRM4geoYCGHnbGv5IOADg7FB4rtK1Vq?usp=sharing\"\n",
        "gdown.download_folder(url, quiet=True, use_cookies=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLtYZ8nW6l0a",
        "outputId": "36d25a56-6c25-49f8-f382-b5d5d5046da0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/model_save_v2/added_tokens.json',\n",
              " '/content/model_save_v2/config.json',\n",
              " '/content/model_save_v2/merges.txt',\n",
              " '/content/model_save_v2/pytorch_model.bin',\n",
              " '/content/model_save_v2/special_tokens_map.json',\n",
              " '/content/model_save_v2/tokenizer_config.json',\n",
              " '/content/model_save_v2/vocab.json']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"model_save_v2\"\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "c-d9NhNLmSZn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(path, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>', local_files_only=True)\n",
        "configuration = GPT2Config.from_pretrained(path, output_hidden_states=False, local_files_only=True)\n",
        "model = GPT2LMHeadModel.from_pretrained(path, config=configuration, local_files_only=True)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncf84H2Kl9Z4",
        "outputId": "b5fef75f-ca35-43cb-a135-ad4ac80d05b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50259, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.eval()\n",
        "prompt = f\"<|startoftext|>{title} {meta} {director} {cast} ::\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample_outputs = model.generate(\n",
        "        generated.to(device), \n",
        "        do_sample=True,   \n",
        "        top_k=50, \n",
        "        max_length=500,\n",
        "        top_p=0.95, \n",
        "        num_return_sequences=3\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtuOJFOCl3wf",
        "outputId": "bc81ead9-db04-4914-cc01-0498a2f0a10c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    comment = tokenizer.decode(sample_output, skip_special_tokens=True).split('::')[1]\n",
        "    print(f\"{i}: {comment}\\n\\n\")"
      ],
      "metadata": {
        "id": "f13hWvAXjkYT",
        "outputId": "e84dc894-692c-46d3-ba41-1f1ff6dca74b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:  Transformers 2 : Une suite dans le même ligné que le premier, un peu mieux. Et, je ne comprends pas les notes car le premier était toute mon enfance. C’est une suite efficace, pas original mais la meilleure suite dans tout les sens. Moi, j’ai adoré l’idée que le premier, quand on voit les effets spéciaux très réussit, qui peut paraitre clairement. Et puis, les 3/4 du film sont encore une fois impressionnant, les effets spéciaux a l’époque sont vraiment spectaculaire et assure le spectacle, c’est quand même effets spéciaux et tout le monde suit les grandes surtout. De plus, il y a une vrai histoire, une mélange entre Science fiction, action et humour bien foutu, avec une bonne dose de suspense et rebondissement. Voila, ce que j’ai apprécié, c’est les 3/4 du film qui sont encore une fois impressionnant. On retrouve tous les 3/4 du début jusqu'à la fin par excellence, je ne suis pas ennuyé une seule seconde mais il envoie peur car il est maitrisé par les acteurs qui joue très bien, rien à dire mais ils sont tous très convaincant : Shia LaBeouf est encore une fois sublime et très inspiré et Josh Duhamel est exceptionnelle et particulièrement excellent comme d’habitude, mieux surtout que d’habitude!!! PS : Déjà, les 3/4 du film sont encore une fois parfaite, les effets spéciaux et tout assure le spectacle, c’est un régal pour les yeux\n",
            "\n",
            "\n",
            "1:  Transformers 2: enfin voila, le premier était dédié qui soit divertissant avec une pointe d’humour et de clin oeil, c’est génial dans son scénario qui tiens bien la route. D’ailleurs, il reprend le très bon boulot de l’humour et les combats sont pas très réussit, les meilleurs de la série sont pas étoffés car l’action assure vraiment, les effets spéciaux assure le spectacle, et les effets spéciaux assure le grand spectacle. Mais c’est pour certains que c’est le cas mais c’est le rythme qui ne s’ennuie pas, de plus, les combat sont nerveuses et l’action est parfois présenté et assez spectaculaire, on a du mal a trouver dans l’univers du premier, il y a des flash back qui sait s’entraite bien, il y en a pas, les quelques choses sont pas aussi long et intense, ils se font plus rien en terme d’action et on a l’impression des le début, c’est assez lent et d’inachevé malgré que le premier n’est pas dépaysant. Voila, coté réalisation, c’est efficace, efficace comme il faut, les effets spéciaux assure le spectacle, les meilleurs sont pas présentés… c’est pour ça que on aurait pu avoir mieux et les acteurs sont jouent bien mais ils ont l’air de s’amusé, je trouve qu’ils n’enlèvent pas. Voila, l’intro est bonne, bien sympa a regarder mais on en reste pas moins\n",
            "\n",
            "\n",
            "2:  Transformers 2: opus tout du long et délire du premier. Vraiment, j’ai était conquis par ce premier épisode car la bande annonce d’un reboot de sa bande et de la suite. Et il faut dire que cela prouve encore avec plaisir car il est toujours aussi remarquable et très convaincant avec aucun temps mort. Et il est porté par une réalisation efficace et dynamique, une mise en scène soignée et de bonne idée pour les effets spéciaux qui est pas excellents, les effets spéciaux de ce premier épisode. Car, c’est très fluide, très stylé, bien filmé pour les scènes de combat et de combats qui sont juste énorme et assure le spectacle (surtout la scène en l’école). Cela c’est magnifiquement bien filmé avec de très beau ralenti et le délire du premier épisode. Ensuite, les acteurs sont vraiment très convaincant et parfait dans leur rôle : la très jolie Josh Duhamel. L’acteur de Josh DuBeouf est très charismatique, toujours aussi marrant dans son rôle, et l’acteur Adam Beachau est juste énorme : très bonne prestation et très belle interprétation. D’ailleurs, l’actrice qui joue les merveilles est très convaincant, parfaite car elle a vraiment un sacré rôle, elle a une très bonne image. Voila, vraiment très bon épisode divertissent et magnifique, j’ai passé un très bon moment et c’est un pl\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1P2MMYDnmLLR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "generate_txt.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}